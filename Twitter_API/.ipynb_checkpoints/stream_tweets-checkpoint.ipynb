{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import sqlite3\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Load the values of access tokens and keys from environmental variables to python variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consumer_key = os.environ.get('consumer_key')# CODE HERE\n",
    "#consumer_secret = os.environ.get('consumer_secret') # CODE HERE\n",
    "#access_token = os.environ.get('access_token') # CODE HERE\n",
    "#access_token_secret =os.environ.get('access_secret') # CODE HERE\n",
    "bearer_token = os.environ.get('bearer_token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Edit function `main` so it can store tweets anywhere (location specified as parameter). The FILTER and LANGUAGES should be parameters as well. Test it with different values and languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB created!\n",
      "Table created\n",
      "Connected!\n",
      "Twitter id: 1602161181242032128\n",
      "Twitter id: 1602161192105017344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream connection closed by Twitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter id: 1602161252490702848\n",
      "Time limit 22s reached 24.128616333007812\n",
      "Disconnected\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "\"\"\"\n",
    "Sream_tweets\n",
    "\"\"\"\n",
    "##########################\n",
    "class TweetStream(tweepy.StreamingClient):\n",
    "    \"\"\"\n",
    "    This class will be activted to listen new tweets (real-times) and\n",
    "    store into DB created\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    def on_connect(self):\n",
    "        #let us know that we have successfully connected to the twitter API\n",
    "        print(\"Connected!\")\n",
    "    \n",
    "    def on_tweet(self, tweet):\n",
    "        #get real-time tweets\n",
    "        if tweet.referenced_tweets == None: #not re-tweets\n",
    "            #connect db\n",
    "            conn = sqlite3.connect(\"../data/tweets.db\")\n",
    "            cur = conn.cursor()\n",
    "            #sql queries\n",
    "            sql_query = \"\"\"\n",
    "                        INSERT INTO tweets (userid,tweet)\n",
    "                        VALUES (?, ?)\n",
    "                        \"\"\"\n",
    "            sql_vals = (tweet.id,tweet.text)\n",
    "            cur.execute(sql_query, sql_vals)\n",
    "            conn.commit()\n",
    "            print(\"Twitter id:\",tweet.id)\n",
    "            #counting time to close stream\n",
    "        if time.time() - self.start_time >= time_limit: #set time_limit outside Class\n",
    "            print(f'Time limit {time_limit}s reached', time.time() - self.start_time)\n",
    "            tweepy.StreamingClient.disconnect(self)\n",
    "            \n",
    "    def on_disconnect(self):\n",
    "        #call after disconnect stream\n",
    "        print(\"Disconnected\")\n",
    "                \n",
    "\n",
    "#set time_limit in second\n",
    "time_limit = 22\n",
    "#create the sqlite3 database to store Data from tweets\n",
    "conn = sqlite3.connect(\"../data/tweets.db\")\n",
    "print(\"DB created!\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE TABLE IF NOT EXISTS tweets (id, userid TEXT, tweet TEXT)\")\n",
    "print(\"Table created\")\n",
    "def main():\n",
    "    stream = TweetStream(bearer_token)\n",
    "    #..Params for functions\n",
    "    # Apply rules\n",
    "    #return current rules\n",
    "    #stream.get_rules()\n",
    "\n",
    "    #add new rules\n",
    "    stream.add_rules(tweepy.StreamRule(value=\"Python has:mentions lang:en\", tag=\"Python\"))\n",
    "    stream.add_rules(tweepy.StreamRule(value=\"Data Science has:mentions lang:en\", tag=\"Data Science\"))\n",
    "\n",
    "    #filter to referenced_tweets to get data in on_tweet\n",
    "    stream.filter(tweet_fields=[\"text\"])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Create File `stream_tweets.py` that can be executed from the Terminal by exporting the code from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Start storing tweets which contain either happy smiley (`:)`) or sad smiley (`:(`) in their text. We will use this dataset during the NLP section. It's good to let the script running for at least 2-3 hours to collect enough data for future modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change add_rules above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Note\n",
    "> the main function runs as an ongoing process and won;t stop until you stop it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
